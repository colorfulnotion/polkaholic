#!/usr/bin/env node

const {
    Command,
    InvalidArgumentError
} = require('commander');
const Crawler = require("./crawler");
const paraTool = require("./paraTool");

function myParseInt(value, dummyPrevious) {
    const parsedValue = parseInt(value, 10);
    if (isNaN(parsedValue)) {
        throw new InvalidArgumentError('Not a number.');
    }
    return parsedValue;
}

async function main() {
    let cli_version = '1.0.0'
    const program = new Command();
    program
        .name('polkaholic')
        .description('Polkaholic Indexer')
        .version(`${cli_version}`);

    program.command('crawlblocks')
        .description(`Crawl Blocks of Chain`)
        .usage("2004")
        .argument('<chainID>', 'ChainID to crawl', myParseInt)
        .action(async (chainID, opt) => {
            var crawler = new Crawler();
            let isDevelopment = (process.env.NODE_ENV == "development") ? true : false
            var debugLevel = paraTool.debugErrorOnly
            crawler.setDebugLevel(debugLevel) // TODO
            await crawler.assetManagerInit();
            let [unsubscribeFinalizedHeads, unsubscribeStorage, unsubscribeRuntimeVersion] = await crawler.crawlBlocks(chainID);
            // do not process.exit
        });

    program.command('crawltraces')
        .description(`Crawl Traces of chain`)
        .usage("2004")
        .argument('<chainID>', 'ChainID to crawl traces for', myParseInt)
        .option('-n <n>', 'Shard #', 0, myParseInt)
        .option('-m, --nmax <nmax>', 'Shard Max', 1, myParseInt)
        .option('--lookbackDays <lookbackDays>', 'Lookback days', 10, myParseInt)
        .action(async (chainID, opt) => {
            let lookback = (Math.random() < .01) ? 7 : 1;
            let n = opt.n;
            let m = opt.nmax;
            let lookbackDays = opt.lookbackDays;
            if (chainID >= 0) {
                var crawler = new Crawler();
                await crawler.assetManagerInit();
                await crawler.crawlTraces(chainID, ["mod", n, m], lookback);
                await crawler.release(5000);
            } else {
                do {
                    var crawler = new Crawler();
                    await crawler.assetManagerInit();
                    await crawler.crawlTracesRandom();

                    const mu = process.memoryUsage();
                    let field = "heapUsed";
                    const gbNow = mu[field] / 1024 / 1024 / 1024;
                    const gbRounded = Math.round(gbNow * 100) / 100;
                    console.log(`Heap allocated ${gbRounded} GB`);
                    if (gbRounded > 1) {
                        process.exit(1);
                    }
                    await crawler.release(5000);
                } while (true);
            }
        })

    program.command('indexchain')
        .description(`Index Specific Chain or random chain`)
        .usage("2004")
        .option('-c, --chainID <chainID>', 'ChainID to index', myParseInt)
        .action(async (chainID, opt) => {
            if (chainID >= 0) {
                let chain = await crawler.getChain(chainID);
                await crawler.indexChain(chain, 60, true, true);
                await crawler.sleep(3 * 1000);
                process.exit(0);
            } else {
                do {
                    let crawler = new Crawler();
                    await crawler.assetManagerInit();
                    let indexed = await crawler.indexChainRandom();
                    if (indexed) {
                        await crawler.release(3 * 1000);
                    } else {
                        await crawler.release(20 * 1000);
                    }
                } while (true);
            }
        })

    program.command('auditchain')
        .description(`Audit Chain for any missing blocks`)
        .usage("2004")
        .argument('<chainID>', 'ChainID to audit', myParseInt)
        .action(async (chainID, opt) => {
            var crawler = new Crawler();
            let chain = await crawler.getChain(chainID);
            await crawler.assetManagerInit();
            await crawler.auditChain(chain);
            process.exit(0);
        });

    program.command('backfill')
        .description(`Backfill missing blocks (can be sharded)`)
        .usage("2004")
        .argument('<chainID>', 'ChainID to backfill', myParseInt)
        .option('-n <n>', `shard [0,nmax-1]`, myParseInt, 0)
        .option('-m, --nmax <nmax>', `# of shards`, myParseInt, 1)
        .option('-l, --lookbackBlocks <lookbackBlocks>', `# of blocks to lookback`, myParseInt, 100000)
        .action(async (chainID, opt) => {
            var crawler = new Crawler();
            await crawler.assetManagerInit();
            let n = opt.n;
            let nmax = opt.nmax;
            let lookbackBlocks = opt.lookbackBlocks;
            var chain = await crawler.getChain(chainID);
            await crawler.crawlBackfill(chain, ["mod", n, nmax], lookbackBlocks, true);
            await crawler.release();
            process.exit(0);
        });


    program.command('identity')
        .description(`Update Identities`)
        .usage("0 identity")
        .argument("<chainID>", "relay chainID (0, 2)", myParseInt)
        .argument("<operation>", "operation (identity, proxy, subidentity)")
        .option('--queryLimit', `Query Limit`, 20000)
        .action(async (chainID, operation, opt) => {
            const IdentityManager = require("./identityManager");
            let debugLevel = 0
            var identityManager = new IdentityManager(debugLevel);
            let queryLimit = opt.queryLimit ? opt.queryLimit : 20000;
            if (operation == "identity") {
                let identityAddrs = await identityManager.getKnownIdentityList(chainID);
                await identityManager.updateOnChainIdentities(chainID, identityAddrs)
                await identityManager.updateOnChainIdentitiesFull(chainID, identityAddrs)
            } else if (operation == "proxy") {
                let proxyAddrs = await identityManager.getKnownProxyList(chainID);
                await identityManager.updateOnChainProxy(chainID, proxyAddrs)
                await identityManager.updateOnChainProxyFull(chainID)
            } else if (operation == "subidentity") {
                let subIdentityAddrs = await identityManager.getKnownSubIdentityList(chainID);
                await identityManager.updateOnChainSubIdentities(chainID, subIdentityAddrs)
                await identityManager.updateOnChainSubIdentitiesFull(chainID)
            }
            process.exit(0);
        });


    program.command('indexblock')
        .description(`Index Block`)
        .usage("22007 195623")
        .argument('<chainID>', 'ChainID', myParseInt)
        .argument('<blockNumber>', 'BlockNumber')
        .action(async (chainID, blockNumber) => {
            blockNumber = paraTool.dechexToInt(blockNumber);
            let crawler = new Crawler();
            crawler.setDebugLevel(paraTool.debugTracing)
            let chain = await crawler.getChain(chainID);
            await crawler.setupAPI(chain);
            await crawler.assetManagerInit();
            await crawler.setupChainAndAPI(chainID);
            let blockHash = await crawler.getBlockHashFinalized(chainID, blockNumber)
            let t2 = null
            if (!blockHash || true) {
                t2 = {
                    chainID,
                    blockNumber,
                    crawlBlockEVM: 1,
                    crawlReceiptsEVM: 1,
                    crawlTraceEVM: 1
                };
            }
            if (t2) {
                let x = await crawler.crawl_block_trace(chain, t2)
                blockHash = x[6];
                console.log("XXXX", blockHash);
            }
            await crawler.index_block(chain, blockNumber, blockHash);
            process.exit(0);
        })

    program.command('indexperiods')
        .argument('<chainID>', 'ChainID', myParseInt)
        .argument('<logDT>', 'Date')
        .argument('<hrs>', 'Hours (comma separated)')
        .description(`Index Periods of a specific chain / day / hrs`)
        .usage("2004 2023-02-10 20,23")
        .action(async (chainID, logDT, hrs, opts) => {
            let isDevelopment = (process.env.NODE_ENV == "development") ? true : false
            var debugLevel = paraTool.debugErrorOnly
            if (isDevelopment) {
                debugLevel = paraTool.debugTracing
                console.log(`[isDevelopment:${isDevelopment}] debugLevel: ${debugLevel}`)
            }

            let crawler = new Crawler();
            // TODO: put this as an option
            //crawler.setDebugLevel(paraTool.debugNoLog)
            //crawler.setDebugLevel(paraTool.debugErrorOnly)
            //crawler.setDebugLevel(paraTool.debugInfo)
            //crawler.setDebugLevel(paraTool.debugVerbose)
            //crawler.setDebugLevel(paraTool.debugTracing)
            crawler.setDebugLevel(debugLevel)
            await crawler.assetManagerInit();
            hrs = hrs.split(",").map(hr => parseInt(hr, 10));
            for (const hr of hrs) {
                await crawler.indexPeriod(chainID, logDT, hr);
            }
            process.exit(0);
        })

    program.command('indexblocks')
        .description(`Index Blocks with SQL`)
        .usage("2011")
        .argument('<chainIDs>', 'ChainIDs (comma-separated)', myParseInt)
        .action(async (chainIDs, opts) => {
            await manager.indexBlocks(chainIDs);
            process.exit(0);
        })

    program.command('reindex')
        .description(`Reindex chain`)
        .usage("22085 -n 3 -nmax 10")
        .argument('<chainID>', 'ChainID', myParseInt)
        .option('-n <n>', 'Shard', 0)
        .option('-m, --nmax <nmax>', 'Shard Max', 1)
        .action(async (chainID) => {
            let crawler = new Crawler();
            // TODO: make option
            crawler.setDebugLevel(paraTool.debugErrorOnly)
            let n = opt.n;
            let nmax = opt.nmax;
            let chain = await crawler.getChain(chainID);
            await crawler.assetManagerInit();
            await crawler.indexChain(chain, 60, false, false, true, ["mod", n, nmax]);
            process.exit(0);
        })


    program.command('updateassetpricelog')
        .description(`Update Asset Prices derives for chain or across the whole network`)
        .usage("-c 2004")
        .option('-c, --chainID <chainID>', 'ChainID to compute asset prices for', myParseInt, -1)
        .action(async (opt) => {
            let chainID = opt.chainID;
            var PriceManager = require("./priceManager");
            if (chainID == -1) {
                let chainIDs = [2006, 2004];
                let priceManager = new PriceManager();
                for (const chainID of chainIDs) {
                    await priceManager.updateAssetPriceLog(chainID, "latest");
                }
                await priceManager.computeBestCrossChainPriceUSD();
            } else {
                let priceManager = new PriceManager();
                await priceManager.updateAssetPriceLog(chainID);
                await priceManager.computeBestCrossChainPriceUSD();
            }
            process.exit(0);
        });

    program.command('pricefeed')
        .description(`Update Asset Prices from coingecko`)
        .option('-s, --startDT <startDT>', 'Start Date', null)
        .option('-e, --endDT <endDT>', 'End Date', null)
        .action(async (opt) => {
            var PriceManager = require("./priceManager");
            let manager = new PriceManager();
            await manager.init();
            if (opt.startDT && opt.endDT) {
                let startTS = paraTool.logDT_hr_to_ts(log.startDT, 0);
                let endTS = paraTool.logDT_hr_to_ts(log.endDT, 0);
                await manager.getCoinPricesRange(startTS, endTS);
            } else {
                await manager.getCoinPrices(0);
            }
            process.exit(0);
        });

    program.command('backupchains')
        .description(`Backup chains`)
        .action(async (opt) => {
            var manager = new Manager();
            await manager.backupChains(manager.GC_BIGTABLE_INSTANCE, manager.GC_BIGTABLE_CLUSTER);
            process.exit(0);
        })

    program.command('mapchains')
        .description(`Map chains into commands`)
        .action(async (opt) => {
            var Manager = require("./manager");
            var manager = new Manager();
            await manager.mapChains((c) => {
                console.log(`./polkaholic auditchain ${c.chainID};`)
                console.log(`./polkaholic backfill ${c.chainID};`)
            });
            process.exit(0);
        })

    await program.parseAsync(process.argv);
}

main()
    .then(() => {
        // do not process.exit(0) here
    })
    .catch((e) => {
        console.error('ERROR', e);
        process.exit(1);
    });
